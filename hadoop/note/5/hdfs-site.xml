<configuration>
<!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 -->
<property>
	<name>dfs.nameservices</name>
	<value>ns1</value>
</property>

<!-- ns1下面有两个NameNode，分别是nn1，nn2 -->
<property>
	<name>dfs.ha.namenodes.ns1</name>
	<value>nn1,nn2</value>
</property>

<!-- nn1的RPC通信地址 -->
<property>
	<name>dfs.namenode.rpc-address.ns1.nn1</name>
	<value>nn1:9000</value>
</property>

<!-- nn1的http通信地址 -->
<property>
	<name>dfs.namenode.http-address.ns1.nn1</name>
	<value>nn1:50070</value>
</property>

<!-- nn2的RPC通信地址 -->
<property>
	<name>dfs.namenode.rpc-address.ns1.nn2</name>
	<value>nn2:9000</value>
</property>

<!-- nn2的http通信地址 -->
<property>
	<name>dfs.namenode.http-address.ns1.nn2</name>
	<value>nn2:50070</value>
</property>

<!-- 指定NameNode的元数据在JournalNode上的存放位置 -->
<property>
	<name>dfs.namenode.shared.edits.dir</name>
	<value>qjournal://zk1:8485;zk2:8485;zk3:8485/ns1</value>
</property>

<!-- 指定JournalNode在本地磁盘存放数据的位置 -->
<property>
	<name>dfs.journalnode.edits.dir</name>
	<value>/home/hadoop/app/hadoop-2.4.1/journaldata</value>
</property>

<!-- 开启NameNode失败自动切换 -->
<property>
	<name>dfs.ha.automatic-failover.enabled</name>
	<value>true</value>
</property>

<!-- 配置失败自动切换实现方式 -->
<property>
	<name>dfs.client.failover.proxy.provider.ns1</name>
	<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>

<!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行-->
<property>
	<name>dfs.ha.fencing.methods</name>
	<value>
		sshfence
		shell(/bin/true)
	</value>
</property>

<!-- 使用sshfence隔离机制时需要ssh免登陆 -->
<property>
	<name>dfs.ha.fencing.ssh.private-key-files</name>
	<value>/home/hadoop/.ssh/id_rsa</value>
</property>

<!-- 配置sshfence隔离机制超时时间 -->
<property>
	<name>dfs.ha.fencing.ssh.connect-timeout</name>
	<value>30000</value>
</property>
</configuration>
