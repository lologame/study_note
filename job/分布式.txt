Redis
    特点：
        Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。
        Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
        Redis支持数据的备份，即master-slave模式的数据备份。

    数据类型：
        1.字符串
        2.Lists：按插入顺序排序的字符串集合，通过链表实现 
                 eg:lpush mylist a b c 左插入a,b,c  返回mylist的元素个数
                    lpop  mylist  返回删除的元素
        3.Sets：不重复且无序的字符串集合
                > sadd myset 1 2 3
                (integer) 3
                > smembers myset
                1. 3
                2. 1
                3. 2
                > sismember myset 3
                (integer) 1
                > sismember myset 30
                (integer) 0

        4.Sorted Sets：每个字符串元素关联一个score，按score排序
            > zadd hackers 1940 "Alan Kay"
            (integer) 1
            > zadd hackers 1957 "Sophie Wilson"
            (integer 1)
            > zadd hackers 1953 "Richard Stallman"
            (integer) 1
            > zadd hackers 1949 "Anita Borg"
            (integer) 1
            > zadd hackers 1965 "Yukihiro Matsumoto"
            (integer) 1
            > zadd hackers 1914 "Hedy Lamarr"
            (integer) 1
            > zadd hackers 1916 "Claude Shannon"
            (integer) 1
            > zadd hackers 1969 "Linus Torvalds"
            (integer) 1
            > zadd hackers 1912 "Alan Turing"
            (integer) 1
            > zrange hackers 0 -1
            1) "Alan Turing"
            2) "Hedy Lamarr"
            3) "Claude Shannon"
            4) "Alan Kay"
            5) "Anita Borg"
            6) "Richard Stallman"
            7) "Sophie Wilson"
            8) "Yukihiro Matsumoto"
            9) "Linus Torvalds"

        5.Hashes： 由field和value组成的map，filed和value都是字符串
                   eg:> hmset user:1000 username antirez birthyear 1977 verified 1
                        OK
                      > hget user:1000 username
                        "antirez"

    redis可以设置key的生存时间

    Lua脚本
        Redis 使用单个 Lua 解释器去运行所有脚本，并且， Redis 也保证脚本会以原子性(atomic)的方式执行： 当某个脚本正在运行的时候，不会有其他脚本或 Redis 命令被执行。
        
        eg:
        > eval "return redis.call('set','foo','bar')" 0
        OK
        > eval "return redis.call('set',KEYS[1],'bar')" 1 foo
        OK

        所有的 Redis 命令，在执行之前都会被分析，籍此来确定命令会对哪些键进行操作。因此要求使用正确的形式来传递键(key)

        Redis 保证所有被运行过的脚本都会被永久保存在脚本缓存当中，这意味着，当 EVAL 命令在一个 Redis 实例上成功执行某个脚本之后，随后针对这个脚本的所有 EVALSHA 命令都会成功执行。EVALSHA

    EXPIRE key seconds 可以设置key的过期时间
        Redis keys过期有两种方式：被动和主动方式。
        主动式：用户访问时key会被发现并主动的过期。
        被动式：每隔10s随机抽选20个key进行过期检测

    Redis内存回收支持近似LRU(最近最少使用)

    事务：
        MULTI指令开启事务,指令入队成功显示QUEUED，EXEC执行事务，EXEC后发生错误不会回滚,DISCARD放弃事务
        
        redis不支持事务回滚

        Watch命令可以提供乐观锁机制
            eg：
                WATCH mykey
                val = GET mykey
                val = val + 1
                MULTI
                SET mykey $val
                EXEC
            在 WATCH 执行之后， EXEC 执行之前， 有其他客户端修改了 mykey 的值， 那么当前客户端的事务就会失败。

    分区：
        分区方案：
            范围分区，将不同范围的对象映射到不同的redis实例。缺点：需要维护映射关系。
            散列分区：对键名散列 **一致性哈希（将key和redis实例放在同一个哈希环上，解决了动态扩容缩容的问题）**
        分区实现方案：
            客户端分区、代理分区、查询路由（客户端随机请求一个实例，该实例将请求转发到正确的节点）
        分区的缺点：
            多个key的操作，多个key的事务
        如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。
        如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。
        预分片技术：
            解决动态扩容缩容问题。一开始就再一台服务器上开启多个redis节点。之后使用redis复制技术实现迁移。
    
    复制：
        一个Master可以有多个Slaves。
        复制在Master端和slave端都是非阻塞的，同步时依旧可以接收查询
        复制的流程：
            在Slave启动并连接到Master之后，它将主动发送一个SYNC命令。此后Master将启动后台存盘进程，同时收集所有接收到的用于修改数据集的命令，在后台进程执行完毕后，Master将传送整个数据库文件到Slave，以完成一次完全同步。而Slave服务器在接收到数据库文件数据之后将其存盘并加载到内存中。此后，Master继续将所有已经收集到的修改命令，和新的修改命令依次传送给Slaves，Slave将在本次执行这些数据修改命令，从而达到最终的数据同步。
            如果Master和Slave之间的链接出现断连现象，Slave可以自动重连Master，但是在连接成功之后，一次完全同步将被自动执行。

    持久化：
        AOF：记录每次对服务器写的操作
        RDB：快照机制

        RDB优点：RDB在保存RDB文件时父进程唯一需要做的就是fork出一个子进程,接下来的工作全部由子进程来做，父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能.与AOF相比,在恢复大的数据集的时候，RDB方式会更快。
        RDB缺点：数据丢失。大数据集的fork耗时，导致响应客户端延时高。

        AOF优点：自动重写，易读。
        AOF缺点：相同数据集AOF文件更大，载入慢。

    Sentinel：
        任务：
            1.监控master和slave的运行是否正常
            2.故障提醒
            3.自动迁移

Kafka
    每个Topic分为多个partition，每个partition对应一个逻辑日志
    物理上，一个日志为相同大小的一组分段文件。每次生产者发布消息到一个分区，代理就将消息追加到最后一个段文件中。当发布的消息数量达到设定值或者经过一定的时间后，段文件真正写入磁盘中。写入完成后，消息公开给消费者。
    消费者向代理发出异步拉请求，准备字节缓冲区用于消费。每个异步拉请求都包含要消费的消息偏移量。
    一个Topic可以认为是一类消息，每个topic将被分成多partition(区),每个partition在存储层面是append log文件。任何发布到此partition的消息都会被直接追加到log文件的尾部，每条消息在文件中的位置称为offset（偏移量）,partition是以文件的形式存储在文件系统中。
    partition为最小的并行消费单位
    发布者发到某个topic的 消息会被均匀的分布到多个part上（随机或根据用户指定的回调函数进行分布），broker收到发布消息往对应part的最后一个segment上添加 该消息，当某个segment上的消息条数达到配置值或消息发布时间超过阈值时，segment上的消息会被flush到磁盘，只有flush到磁盘上的 消息订阅者才能订阅到，segment达到一定的大小后将不会再往该segment写数据，broker会创建新的segment。